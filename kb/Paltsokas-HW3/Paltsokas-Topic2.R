# getwd()
# setwd("C:\\Users\\user\\Desktop\\ΕΑΠ\\DAMA 51\\My_assignments\\HW2\\R_scripts")

cat("####### Topic 2a #######\n")
################ Topic 2a ################
#install and load AppliedPredictiveModeling
#install.packages("AppliedPredictiveModeling")
#install.packages("Metrics")
library(AppliedPredictiveModeling)
library(caret)
library(Metrics)
# load the abalone dataset
data(abalone)
# exclude the Type and Rings variables creating a subset of the dataframe which is store in the df_data variable
df_data <- subset(abalone, select = -c(Type, Rings))
# store the Rings variable to y
y <- abalone$Rings

# According to caret (version 6.0-94) documentation filterVarImp takes the df_data dataframe and the y vector and creates a 
# dataframe with variable importance in the Overall column
ranking <- filterVarImp(df_data, y)
# sort the variables by decreasing importance
ranking$varNames <- rownames(ranking)
# We use the function 'order' which returns the indices that would sort the variables according to the Overall value and we reverse
# the order by using the negation operator (-). Then the row order is rearranged accordingly and the result is a new dataframe
# stored as ranked_vars
ranked_vars <- ranking[order(-ranking$Overall),]
ranked_vars$varNames
ranked_vars_rounded <- round(ranked_vars$Overall, 3)
print(ranked_vars)
cat("\n")
print(ranked_vars_rounded)
cat("\n")

################ Topic 2b ################
# Select top 2 most important variables from df_data
x_rank <- df_data[, head(ranked_vars,2)$varNames]
# Scale the selected variables to have mean 0 and standard deviation 1 and convert to data frame
x_rank <- as.data.frame(scale(x_rank))
# Fit linear regression model using scaled variables as predictors
# The formula y ~ . specifies that y should be modeled as a function of all the columns in x_rank
model_rank <- lm(y ~ ., data=x_rank)
# Calculate and round MSE of model predictions to 3 decimal places
round(mse(y, predict(model_rank, x_rank)), 3)

cat("####### Topic 2b #######")
cat("\nTop-ranked variables:\n")
print(ranked_vars$varNames[1:2])
cat("\nImportance scores:\n")
print(round(ranked_vars$Overall[1:2], 3))
cat("\nThe Mean Squared Error (MSE) of the linear regression model of the top two ranked variables in terms of importacne is", round(mse(y, predict(model_rank, x_rank)), 3), "\n")

################ Topic 2c ################
# Normalize df_data so that each variable has mean 0 and standard deviation 1. 
scaled_data <- scale(df_data)
# Perform PCA on the normalized data to reduce dimensionality and identify patterns in the data structure
results_PCA <- prcomp(scaled_data)
# Extract the names of the principal components (e.g., PC1, PC2) generated by PCA for later use in data frames
PCnames = colnames(results_PCA$rotation)
# Extract the standard deviations of each principal component, reflecting the amount of variance each component captures
sd <- results_PCA$sdev
# Calculate the percentage of total variance explained by each principal component to assess their importance
variance_explained_pct <- round((sd^2) / sum(sd^2),3)
# Combine the principal components and their respective percentages of variance explained into a structured dataframe for analysis
variance_explained_df <- data.frame(Principal_Component = PCnames, Variance_Explained_Pct = variance_explained_pct, row.names = NULL)
# Calculate the combined percentage of total variance explained by the first two principal components to understand the initial data reduction impact
variance_explained_first_two <- sum(variance_explained_df$Variance_Explained_Pct[1:2])

cat("\n####### Topic 2c #######\n")
cat("Variance Explained per Principal Component:\n")
for (i in 1:nrow(variance_explained_df)) {
  cat(variance_explained_df$Principal_Component[i], "- Variance Explained: ", 
      variance_explained_df$Variance_Explained_Pct[i], "\n")
}
cat("\nTotal Variance Explained by the First Two Principal Components:", round(variance_explained_first_two * 100, 3), "%\n")

################ Topic 2d ################
x_PCA <- results_PCA$x
# Create dataframe using the first two principal components, which encapsulates the majority of variance
x_PCA2 <- as.data.frame(x_PCA[,1:2])
x_PCA2$age <- y
# Perform linear regression using the first two principal components as predictors to model 'age'
model_PCA <- lm(age ~ ., data = x_PCA2)
# Calculate the MSE between the observed and predicted 'age' values
MSE = round(mse(x_PCA2$age, predict(model_PCA, x_PCA2)), 3)

cat("\n####### Topic 2d #######\n")
cat("The Mean Squared Error (MSE) of the linear regression model of the first two principal components is",MSE)
cat("\n\nComment:\nThe MSE of 6.645 is slightly higher than the first model, indicating a marginally less accurate 
    fit to the data when using these principal components as predictors. The principal components represent linear 
    combinations of the original variables that capture the most variance across the dataset, but not necessarily 
    the variance most relevant to predicting the age 'y'.")



